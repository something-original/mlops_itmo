# itmo_mlops

Проект по курсу MLOps в ИТМО.\
**Студент: Киселев Георгий**

## Описание проекта

Проект посвящен анализу корпоративных документов (счета, договоры и т.д). Пользователь загружает 2 файла (PDF, Word или изображения), например, оригинал документа и его предполагаемую копию. На выходе пользователь получает статистику выявленных расхождений и оценку степени схожести документов. Используются OCR и NLP пайплайны.

## Git Workflow

При работе над проектом используется Github Flow: есть релизная ветка main (master), на каждую новую фичу (домашнее задание) создается отдельная ветка. После завершения работы над фичей (домашним заданием), проверки преподавателем и исправления ошибок эта ветка вливается в main. Выбор модели ветвления обусловлен ее удобством при работе над проектом одному, так как не нужно создавать и поддерживать большое количество веток одновременно.


## Работа с системой версионирования

В качестве системы версионирования выбран DVC, хранилище - Google Drive. Для загрузки датасета создайте файл ```config.local``` в директории ```.dvc```. Структура содержимого файла:

```
['remote "mygdrive"']
    gdrive_client_id = <gdrive_client_id>
    gdrive_client_secret = <gdrive_client_secret>
    gdrive_service_account_json_file_path = ../credentials.json
```
Файл ```credentials.json``` и остальные секреты можно получить, следуя [инструкции](https://dvc.org/doc/user-guide/data-management/remote-storage/google-drive#using-service-accounts)

Далее можно загружать и выгружать датасет и модели, используя команды ```dvc pull``` и ```dvc push``` соответственно.


## Запуск пайплайна

В качестве менеджера пайплайнов выбран Snakemake. Пайплайн включает в себя загрузку датасета из системы версионирования, разбиение датасета на тренировочный/валидационный/тестовый, предобработку из csv в json, обучение моделей ```Parseq``` и ```Master```, загрузку чекпоинтов и статистики в систему контроля версий. Пропорции разбиения датасета определены в файле ```snakemake_config.yaml```. 

Для локального запуска пайплайна выполните активацию локального окружения, установку зависимостей, затем команду ```poetry run snakemake -s Snakefile --cores all```.\

Для запуска пайплайна в Docker:

1. **Сборка образа:**
   ```docker build -f Dockerfile.snakemake -t snakemake-ocr .```
2. **Запуск пайплайна:**\
   Linux:
   ```docker run --rm -it -v $(pwd):/workspace snakemake-ocr```\
   Windows:
   ```docker run --rm -it -v %cd%:/workspace snakemake-ocr```


## Генерация датасета и обучение модели

В директории **(ocr_model_training)** находятся скрипты для генерации датасета и обучения моделей компьютерного зрения с использованием фреймворка Doctr. Исходный датасет с изображениями (текст только на кириллице) хранится на [стороннем репозитории](https://huggingface.co/datasets/DonkeySmall/OCR-Cyrillic-Printed-1) HuggingFace. Он берется за основу, в дополнение к нему генерируются собственные изображения, включающие не только кириллицу, но и латиницу и специальные символы. После генерации полученный датасет сжимается и с помощью DVC загружается в [собственный репозиторий](https://drive.google.com/drive/folders/1KKniHEA6O4gRKIkduOEm67i876b47_o6) на Google Drive, при этом обовляется версия датасета. Далее происходит обучение, валидация и тест моделей Doctr Parseq и Doctr Master на соответствующих данных, после чего обученная модель загружается на HuggingFace. После этого происходит сравнение обеих моделей актуальных версий на тестовой выборке данных, результаты сохраняются в таблицу. 

## Результаты

Результаты сохраняются в файл ```models/scores.json```, который хранится в репозитории с моделями как метаданные. В файле есть информация о метрике на тестовом датасете для каждой модели и о размере и версии датасета, на котором модели обучались, валидировались и тестировались. Метрика считается как процент правильно распознанных букв на своих местах. 

## Используемые инструменты:

 - Для управления зависимостями - poetry
 - Система версионирования - DVC
 - Для больших данных - GIT LFS
 - Линтер - flake8
 - Docker

## Описание CI-пайплайнов

CI-пайплайны реализованы с помощью GitHub Actions и описаны в файлах в папке `.github/workflows.` Пайплайны запускаются при push в любую из веток. Включают в себя проверку линтером, сборку Docker-образа и сборку документации. 


## Запуск проекта

1. Клон репозитория: `git clone https://github.com/something-original/mlops_itmo.git && cd mlops_itmo`
2. Установка зависимостей с помощью poetry: `poetry install --no-root`
3. Для использования pre-commit хуков: `poetry run pre-commit install`
4. Можно использовать Docker: `docker build --tag "mlops_itmo" . ` или docker-compose `docker-compose up`

