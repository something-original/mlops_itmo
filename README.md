# itmo_mlops

Проект по курсу MLOps в ИТМО.\
**Студент: Киселев Георгий**

## Содержание

[1. Описание проекта](#1-описание-проекта)\
[2. Git Workflow](#2-git-workflow)\
[3. Работа с системой версионирования](#3-работа-с-системой-версионирования)\
[4. Запуск пайплайна](#4-запуск-пайплайна)\
[5. Работа с системой трекинга экспериментов](#5-работа-с-системой-трекинга-экспериментов)\
[6. Генерация датасета и обучение модели](#6-генерация-датасета-и-обучение-модели)\
[7. Результаты](#7-результаты)\
[8. Используемые инструменты](#8-используемые-инструменты)\
[9. Описание CI-пайплайнов](#9-описание-ci-пайплайнов)\
[10. Запуск проекта](#10-запуск-проекта)

## 1. Описание проекта

Проект посвящен анализу корпоративных документов (счета, договоры и т.д). Пользователь загружает 2 файла (PDF, Word или изображения), например, оригинал документа и его предполагаемую копию. На выходе пользователь получает статистику выявленных расхождений и оценку степени схожести документов. Используются OCR и NLP пайплайны.

## 2. Git Workflow

При работе над проектом используется Github Flow: есть релизная ветка main (master), на каждую новую фичу (домашнее задание) создается отдельная ветка. После завершения работы над фичей (домашним заданием), проверки преподавателем и исправления ошибок эта ветка вливается в main. Выбор модели ветвления обусловлен ее удобством при работе над проектом одному, так как не нужно создавать и поддерживать большое количество веток одновременно.


## 3. Работа с системой версионирования

В качестве системы версионирования выбран DVC, хранилище - Google Drive. Для загрузки датасета создайте файл ```config.local``` в директории ```.dvc```. Структура содержимого файла:

```
['remote "mygdrive"']
    gdrive_client_id = <gdrive_client_id>
    gdrive_client_secret = <gdrive_client_secret>
    gdrive_service_account_json_file_path = ../credentials.json
```
Файл ```credentials.json``` и остальные секреты можно получить, следуя [инструкции](https://dvc.org/doc/user-guide/data-management/remote-storage/google-drive#using-service-accounts)

Далее можно загружать и выгружать датасет и модели, используя команды ```dvc pull``` и ```dvc push``` соответственно.


## 4. Запуск пайплайна

В качестве менеджера пайплайнов выбран Snakemake. Пайплайн включает в себя загрузку датасета из системы версионирования, разбиение датасета на тренировочный/валидационный/тестовый, предобработку из csv в json, обучение моделей ```Parseq``` и ```Master```, загрузку чекпоинтов и статистики в систему контроля версий. Пропорции разбиения датасета определены в файле ```snakemake_config.yaml```. 

Для локального запуска пайплайна выполните активацию локального окружения, установку зависимостей, затем команду ```poetry run snakemake -s Snakefile --cores all```.\

Для запуска пайплайна в Docker:

1. **Сборка образа:**
   ```docker build -f Dockerfile.snakemake -t snakemake-ocr .```
2. **Запуск пайплайна:**\
   Linux:
   ```docker run --rm -it -v $(pwd):/workspace snakemake-ocr```\
   Windows:
   ```docker run --rm -it -v %cd%:/workspace snakemake-ocr```

## 5. Работа с системой трекинга экспериментов

В качестве системы трекинга экспериментов используется ClearML. Для запуска выполните команду:\
```clearml-init```.\
Далее следуйте инструкциям в консоли, чтобы получить файл ```clearml.conf``` с доступами. Разместите его в корневой директории проекта.\
Работа непосредственно с ClearML (создание Task и тд) реализована внутри моего форка библиотеки Doctr, файл можно посмотреть по [ссылке](https://github.com/something-original/doctr/blob/main/references/recognition/train_pytorch.py).\
Система трекинга экспериментов интегрирована в пайплайн Snakemake и связана с системой контроля версий (так как данные в пайплайне получаются с помощью DVC). Информация о датасете также содержится в ClearML.



## 6. Генерация датасета и обучение модели

В директории **(ocr_model_training)** находятся скрипты для генерации датасета и обучения моделей компьютерного зрения с использованием фреймворка Doctr. Исходный датасет с изображениями (текст только на кириллице) хранится на [стороннем репозитории](https://huggingface.co/datasets/DonkeySmall/OCR-Cyrillic-Printed-1) HuggingFace. Он берется за основу, в дополнение к нему генерируются собственные изображения, включающие не только кириллицу, но и латиницу и специальные символы. После генерации полученный датасет сжимается и с помощью DVC загружается в [собственный репозиторий](https://drive.google.com/drive/folders/1KKniHEA6O4gRKIkduOEm67i876b47_o6) на Google Drive, при этом обовляется версия датасета. Далее происходит обучение, валидация и тест моделей Doctr Parseq и Doctr Master на соответствующих данных, после чего обученная модель загружается на HuggingFace. После этого происходит сравнение обеих моделей актуальных версий на тестовой выборке данных, результаты сохраняются в таблицу. 

## 7. Результаты

Результаты логгируются в ClearML и сохраняются в файл ```models/scores.json```, который хранится в репозитории Google Drive с моделями как метаданные. В файле есть информация о метрике на тестовом датасете для каждой модели и о размере и версии датасета, на котором модели обучались, валидировались и тестировались. Метрика считается как процент правильно распознанных букв на своих местах.


### Анализ результатов

В качестве эксперимента проведено 3 попытки обучения: модели Parseq и Master на полном датасете (210к изображений) и модели Parseq на сокращенном датасете (21к изображений).\
Логи обучения доступны по [ссылке](https://app.clear.ml/projects/c7ae4a5fe6504a8280e0950a66105056/tasks/555fb15c4f884d5a9b2273d36c637dce/execution?columns=selected&columns=type&columns=name&columns=tags&columns=status&columns=project.name&columns=users&columns=started&columns=last_update&columns=last_iteration&columns=parent.name&order=-last_update&filter=&deep=true).

Метрики обучения сведены в таблицу:

| Модель | Кол-во параметров | Кол-во эпох | Размер датасета | ExactMatch | PartialMatch | TrainLoss | ValLoss |
|--------|-------------------|-------------|-----------------|------------|--------------|-----------|---------|
| Master | 58.8М             | 10          | 210к            | 0.65       | 0.66         | 0.26      | 0.17    |
| Parseq | 23.8М             | 10          | 210к            | 0.007      | 0.007        | 2.16      | 9.41    |
| Parseq | 23.8М             | 10          | 21к             | 0.005      | 0.005        | 2.49      | 7.69    |

Графики обучения и другие параметры можно посмотреть по ссылкам (во вкладке scalars, необходимо иметь аккаунт ClearML):\
[Для первого эксперимента в таблице](https://app.clear.ml/projects/331468440d1c46e388796074fb0606bd/experiments/555fb15c4f884d5a9b2273d36c637dce/output/execution)\
[Для второго эксперимента в таблице](https://app.clear.ml/projects/331468440d1c46e388796074fb0606bd/experiments/fc752d6c6f194d478b08b2de7bd3275f/output/execution)\
[Для третьего эксперимента в таблице](https://app.clear.ml/projects/331468440d1c46e388796074fb0606bd/experiments/a480ba828a1845d4bc7cb3597cf0974d/output/execution)

**Примечание:**  
- **ExactMatch** – процент примеров, где все символы распознаны верно.  
- **PartialMatch** – процент примеров, где хотя бы 50% символов распознаны верно.  
- **Loss** – categorical cross-entropy.

**Выводы и анализ:**
Изначально в тренировочной выборке было 21к изображений (0.07 от общего датасета). После обучения модели Parseq принято решение увеличить тренировочный датасет в 10 раз и повторить обучение.

Модель Master показывает высокие значения ExactMatch и PartialMatch (0.65 и 0.66), что говорит о хорошей способности распознавать текст. 
Модель Parseq (23.8М параметров) на полном датасете (210к) демонстрирует низкие значения ExactMatch и PartialMatch (0.007), что указывает на проблемы с точностью распознавания. Высокие значения TrainLoss (2.16) и ValLoss (9.41) и графики обучения с возрастающим loss говорят о том, что модель не сходится и переобучается.

Вероятно, для данной задачи параметров Parseq недостаточно, чтобы распознавать кириллицу, латиницу, цифры и спецсимволы на одном изображении. Необходим подбор гиперпараметров и дополнительные исследования, в то время как Master демонстрирует приемлемый результат, однако в силу в 2 раза большего количества параметров у этой модели значительно больше время инференса.  

## 8. Используемые инструменты:

 - Для управления зависимостями - poetry
 - Система версионирования - DVC
 - Для больших данных - GIT LFS
 - Линтер - flake8
 - Docker

## 9. Описание CI-пайплайнов

CI-пайплайны реализованы с помощью GitHub Actions и описаны в файлах в папке `.github/workflows.` Пайплайны запускаются при push в любую из веток. Включают в себя проверку линтером, сборку Docker-образа и сборку документации. 


## 10. Запуск проекта

1. Клон репозитория: `git clone https://github.com/something-original/mlops_itmo.git && cd mlops_itmo`
2. Установка зависимостей с помощью poetry: `poetry install --no-root`
3. Для использования pre-commit хуков: `poetry run pre-commit install`
4. Можно использовать Docker: `docker build --tag "mlops_itmo" . ` или docker-compose `docker-compose up`

