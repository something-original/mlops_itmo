{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPx9lddg6DQK"
      },
      "source": [
        "# Генерация датасета для задач OCR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwsVewT46Px1"
      },
      "source": [
        "### Подготовка"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "colab = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-7A-d5yBxkyo",
        "outputId": "98ceb869-fde3-4401-a714-3fe70a487d0a"
      },
      "outputs": [],
      "source": [
        "if colab:\n",
        "    !pip install requests\n",
        "    !pip install random_word\n",
        "    !pip install tqdm\n",
        "    !pip install streamlit>=1.0.0\n",
        "    !pip install wandb>=0.10.31\n",
        "    !pip install matplotlib>=3.1.0\n",
        "    !pip install defusedxml\n",
        "    !pip install opencv-python-headless\n",
        "    !pip install anyascii\n",
        "    !pip install wget\n",
        "    !pip install pyyaml\n",
        "    !pip install natsort"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "rNSRndKeyYcV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from random_word import RandomWords\n",
        "import string\n",
        "import shutil\n",
        "import wget\n",
        "import zipfile\n",
        "from dotenv import load_dotenv\n",
        "from huggingface_hub import HfApi, login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9rdM2EAYaY0"
      },
      "source": [
        "#### Загружаем датасет с Hugging Face и распаковываем"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCH17RFdxkyq"
      },
      "source": [
        "Если нужно перегенерировать датасет, в ячейке ниже должно быть True. В таком случае загружаем кириллический датасет с HF и дополняем его своей синтетикой. Иначе загружаем готовый датасет со всеми необходимыми символами"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jLJrtfcYxkyq"
      },
      "outputs": [],
      "source": [
        "generate_dataset = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjiTcu13Q6_d",
        "outputId": "95b2df9e-e782-4eca-c05b-272e21911103"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting files: 100%|██████████| 500002/500002 [13:31<00:00, 616.26it/s] \n"
          ]
        }
      ],
      "source": [
        "if generate_dataset:\n",
        "  file_name = 'data_1.zip'\n",
        "  if not os.path.exists(file_name):\n",
        "    wget.download('https://huggingface.co/datasets/DonkeySmall/OCR-Cyrillic-Printed-1/resolve/main/data_1.zip')\n",
        "  with zipfile.ZipFile(file_name, 'r') as zip_ref:\n",
        "    for file in tqdm(zip_ref.infolist(), desc='Extracting files'):\n",
        "        zip_ref.extract(file, 'dataset')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ooq0GnoH5-DP"
      },
      "source": [
        "### Генерация датасета"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ya6taa8ZeWVP"
      },
      "outputs": [],
      "source": [
        "#русское слово (берем с HF)\n",
        "#русское cлово + знак препинания (берем с HF и добавляем знак) \".,?!:;/%\"\n",
        "#русское слово с дефисом внутри слова\n",
        "#число\n",
        "#число, разделенное точкой или дефисом (01.01.2024)\n",
        "#число + символ валюты или процент\n",
        "#слово или число в скобках, кавычках (с одной стороны или с 2х) \"()\"«»\"\n",
        "#имя (И.И.)\n",
        "#№ + числа\n",
        "#английское слово\n",
        "#электронная почта"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "5esvww02v9dZ"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('arial-cyr.ttf') and generate_dataset:\n",
        "  wget.download('https://huggingface.co/datasets/smthrgnl/arial_cyrillic_font/blob/main/arial-cyr.ttf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrAgeS5o2HdA"
      },
      "source": [
        "Добавляем синтетический датасет"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "B_bzu6VBiTEw"
      },
      "outputs": [],
      "source": [
        "def generate_image_for_word(word, output_directory, image_name):\n",
        "\n",
        "    font_size = random.randint(50, 100)\n",
        "    padding = 20\n",
        "    vertical_padding = 30\n",
        "\n",
        "    try:\n",
        "        font = ImageFont.truetype(\"arial.ttf\", font_size)\n",
        "    except IOError:\n",
        "        try:\n",
        "            font = ImageFont.truetype(\"arialbd.ttf\", font_size)\n",
        "        except IOError:\n",
        "            font = ImageFont.load_default()\n",
        "            font.size = font_size\n",
        "\n",
        "    temp_img = Image.new('RGB', (1, 1))\n",
        "    temp_draw = ImageDraw.Draw(temp_img)\n",
        "\n",
        "    bbox = temp_draw.textbbox((0, 0), word, font=font)\n",
        "    text_width = bbox[2] - bbox[0]\n",
        "    text_height = bbox[3] - bbox[1]\n",
        "\n",
        "    ascent, descent = font.getmetrics()\n",
        "\n",
        "    img_width = text_width + 2 * padding\n",
        "    img_height = ascent + descent + vertical_padding\n",
        "\n",
        "    bg_color = (random.randint(110, 255), random.randint(110, 255), random.randint(110, 255))\n",
        "    text_color = (random.randint(0, 100), random.randint(0, 100), random.randint(0, 100))\n",
        "\n",
        "    img = Image.new('RGB', (img_width, img_height), color=bg_color)\n",
        "    d = ImageDraw.Draw(img)\n",
        "\n",
        "    text_position = (padding, (img_height - text_height) // 2 - descent // 2)\n",
        "\n",
        "    d.text(text_position, word, fill=text_color, font=font)\n",
        "\n",
        "    image_path = os.path.join(output_directory, image_name)\n",
        "    img.save(image_path, 'JPEG')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "MfCdZqsafYNY"
      },
      "outputs": [],
      "source": [
        "r = RandomWords()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "9vgkH7pD35Cp"
      },
      "outputs": [],
      "source": [
        "punctuation = \".,?!:;/\"\n",
        "currency = \"$\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "wqp6L1Q8YDun"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 300000/500000 [44:21<29:34, 112.74it/s]  \n"
          ]
        }
      ],
      "source": [
        "random.seed(42)\n",
        "limit = 300000\n",
        "\n",
        "if generate_dataset:\n",
        "\n",
        "  words_df = pd.DataFrame(columns=['filename', 'words'])\n",
        "  filenames, words = [], []\n",
        "\n",
        "  if 'images' in os.listdir('dataset'):\n",
        "    shutil.rmtree('dataset/images')\n",
        "  os.makedirs('dataset/images')\n",
        "\n",
        "  with open('./dataset/1.txt', 'r', encoding='utf-8') as labels_txt:\n",
        "\n",
        "      counter = 0\n",
        "\n",
        "      for line in tqdm(labels_txt.readlines()):\n",
        "        if counter == limit:\n",
        "          break\n",
        "        rand = random.randint(1, 43)\n",
        "        splitted_line = line.split('`')\n",
        "        img_name = splitted_line[0][2:]\n",
        "        img_value = splitted_line[1][:-1] if splitted_line[1][-1] == '\\n' else splitted_line[1]\n",
        "\n",
        "        if rand in range(1, 15): #обычное слово на русском языке\n",
        "            shutil.copy(f'dataset/1/{img_name}', f'dataset/images/{img_name}')\n",
        "        else:\n",
        "          if rand in range(16, 19): #слово со знаком препинания\n",
        "            img_value = img_value + random.choice(punctuation)\n",
        "\n",
        "          elif rand in range(20, 22): #слово с дефисом\n",
        "            index = random.randint(1, len(img_value) - 2)\n",
        "            img_value = img_value[:index] + '-' + img_value[index:]\n",
        "\n",
        "          elif rand in range(23, 25): #число\n",
        "            img_value = ''.join(random.choices(string.digits, k=random.randint(1, 12)))\n",
        "\n",
        "          elif rand in range(26, 28): #число с разделителями\n",
        "            num = ''.join(random.choices(string.digits, k=random.randint(5, 12)))\n",
        "            n = random.randint(0, 1)\n",
        "            sep = '.' if n == 0 else '-'\n",
        "            index1 = random.randint(1, len(num) // 2)\n",
        "            index2 = random.randint(len(num) // 2 + 1, len(num) - 2)\n",
        "            img_value = ''.join(num[:index1]) + sep + ''.join(num[index1:index2]) + sep + ''.join(num[index2:])\n",
        "\n",
        "          elif rand in range(29, 31): #число + символ валюты, номер или процент\n",
        "            num = ''.join(random.choices(string.digits, k=random.randint(1, 6)))\n",
        "            n = random.randint(0, 2)\n",
        "            if n == 0:\n",
        "              suffix = '%'\n",
        "              img_value = num + suffix\n",
        "            elif n == 1:\n",
        "              suffix = currency\n",
        "              img_value = num + suffix\n",
        "            else:\n",
        "              img_value = '№' + num\n",
        "\n",
        "          elif rand in range(32, 34): #объект в скобках\n",
        "            n = random.randint(0, 8)\n",
        "            if n == 0:\n",
        "              img_value = '(' + img_value\n",
        "            elif n == 1:\n",
        "              img_value = img_value + ')'\n",
        "            elif n == 2:\n",
        "              img_value = '(' + img_value + ')'\n",
        "            elif n == 3:\n",
        "              img_value = '«' + img_value\n",
        "            elif n == 4:\n",
        "              img_value = img_value + '»'\n",
        "            elif n == 5:\n",
        "              img_value = '«' + img_value + '»'\n",
        "            elif n == 6:\n",
        "              img_value = '\\\"' + img_value\n",
        "            elif n == 7:\n",
        "              img_value = img_value + '\\\"'\n",
        "            elif n == 8:\n",
        "              img_value = '\\\"' + img_value + '\\\"'\n",
        "\n",
        "\n",
        "          elif rand in range(35, 36): # инициалы (2 заглавных буквы с точками)\n",
        "            img_value = '.'.join([random.choice('АБВГДЕЖЗИКЛМНОПРСТУФХЦЧШЩЭЮЯ') for _ in range(2)]) + '.'\n",
        "\n",
        "          elif rand in range(37, 41): # английское слово\n",
        "            eng_word = r.get_random_word()\n",
        "            seed = random.randint(1, 3)\n",
        "            if seed == 2:\n",
        "              eng_word = eng_word[0].upper() + eng_word[1:]\n",
        "            if seed == 3:\n",
        "              eng_word = eng_word.upper()\n",
        "            if len(eng_word) > 31:\n",
        "              eng_word = eng_word[0:31]\n",
        "            img_value = eng_word\n",
        "\n",
        "          elif rand in range(42, 43): # почтовый адрес (в рандомное место вставляем _)\n",
        "            mail = r.get_random_word()\n",
        "            if len(mail) > 13:\n",
        "              mail = mail[0:12]\n",
        "            index = random.randint(1, len(mail))\n",
        "            server = r.get_random_word()\n",
        "            if len(server) > 13:\n",
        "              server = server[0:12]\n",
        "            k = random.randint(1, 3)\n",
        "            if k == 3:\n",
        "              mail = mail[:index] + '_' + mail[index:]\n",
        "            domain = ''.join(random.choices(string.ascii_lowercase, k=random.randint(2, 3)))\n",
        "            img_value = mail + '@' + server + '.' + domain\n",
        "\n",
        "          img_name = img_name.replace('_1_', '_2_')\n",
        "          fs = random.randint(22, 45)\n",
        "          generate_image_for_word(word=img_value, image_name=img_name, output_directory='./dataset/images')\n",
        "\n",
        "          if img_value[0] == '\\\"':\n",
        "            img_value = '\\\\' + img_value\n",
        "          if img_value[-1] == '\\\"':\n",
        "            img_value = img_value[:-1] + '\\\\' + '\\\"'\n",
        "\n",
        "        filenames.append(img_name)\n",
        "        words.append(img_value)\n",
        "        counter += 1\n",
        "\n",
        "  words_df['filename'] = filenames\n",
        "  words_df['words'] = words\n",
        "  words_df.to_csv('dataset/labels.csv', sep=';', index=False, encoding='utf-8-sig')\n",
        "\n",
        "  if '1.txt' in os.listdir('dataset'):\n",
        "    os.remove('dataset/1.txt')\n",
        "  if '1' in os.listdir('dataset'):\n",
        "    shutil.rmtree('dataset/1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "def zip_folder(folder_path, output_path):\n",
        "\n",
        "    with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for root, dirs, files in os.walk(folder_path):\n",
        "            for file in tqdm(files):\n",
        "                file_path = os.path.join(root, file)\n",
        "\n",
        "                arcname = os.path.relpath(file_path, start=folder_path)\n",
        "                zipf.write(file_path, arcname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "def push_to_huggingface(zip_path, repo_id, commit_message=\"Update OCR dataset\"):\n",
        "\n",
        "    api = HfApi()\n",
        "    api.upload_file(\n",
        "        path_or_fileobj=zip_path,\n",
        "        path_in_repo=os.path.basename(zip_path),\n",
        "        repo_id=repo_id,\n",
        "        repo_type=\"dataset\",\n",
        "        commit_message=commit_message\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "def zip_and_push_to_hub(dataset_folder, zip_filename, repo_id):\n",
        "\n",
        "    load_dotenv()\n",
        "    \n",
        "    if zip_filename in os.listdir():\n",
        "        os.remove(zip_filename)\n",
        "    print(f\"Zipping {dataset_folder} to {zip_filename}...\")\n",
        "    zip_folder(dataset_folder, zip_filename)\n",
        "    \n",
        "    hf_token = os.getenv(\"HF_TOKEN\")\n",
        "    if not hf_token:\n",
        "        raise ValueError(\"HF_TOKEN not found in .env file\")\n",
        "    login(token=hf_token)\n",
        "    \n",
        "    print(f\"Pushing {zip_filename} to {repo_id}...\")\n",
        "    push_to_huggingface(zip_filename, repo_id)\n",
        "    \n",
        "    print(\"Dataset update completed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Zipping dataset to dataset.zip...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.24it/s]\n",
            "100%|██████████| 300000/300000 [49:49<00:00, 100.36it/s]\n",
            "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pushing dataset.zip to smthrgnl/ocr_cyrillic_english...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "dataset.zip: 100%|██████████| 1.41G/1.41G [07:51<00:00, 2.99MB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset update completed successfully!\n"
          ]
        }
      ],
      "source": [
        "push_to_hub = True\n",
        "dataset_folder = \"dataset\"\n",
        "zip_filename = \"dataset.zip\"\n",
        "repo_id = \"smthrgnl/ocr_cyrillic_english\"\n",
        "\n",
        "if push_to_hub:\n",
        "    zip_and_push_to_hub(dataset_folder, zip_filename, repo_id)\n",
        "else:\n",
        "    zip_folder(dataset_folder, zip_filename)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "hw-2-_-svfkea-py3.12",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
